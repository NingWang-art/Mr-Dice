import argparse
import logging
import json
from typing import List, Optional, TypedDict, Literal
from pathlib import Path
from datetime import datetime
import hashlib
from anyio import to_thread
import asyncio

from optimade.client import OptimadeClient
from dp.agent.server import CalculationMCPServer

# Pull all helpers + provider sets from your utils.py
from utils import *

# === CONFIG ===
BASE_OUTPUT_DIR = Path("materials_data")
BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

MAX_RETURNED_STRUCTS = 100

# === ARG PARSING ===
def parse_args():
    parser = argparse.ArgumentParser(description="OPTIMADE Materials Data MCP Server")
    parser.add_argument('--port', type=int, default=50001, help='Server port (default: 50001)')
    parser.add_argument('--host', default='0.0.0.0', help='Server host (default: 0.0.0.0)')
    parser.add_argument('--log-level', default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help='Logging level (default: INFO)')
    try:
        return parser.parse_args()
    except SystemExit:
        class Args:
            port = 50001
            host = '0.0.0.0'
            log_level = 'INFO'
        return Args()


# === RESULT TYPE (what each tool returns) ===
Format = Literal["cif", "json"]

class FetchResult(TypedDict):
    output_dir: Path             # folder where results are saved
    cleaned_structures: List[dict]  # list of cleaned structures
    n_found: int                    # number of structures found (0 if none)


# === MCP SERVER ===
args = parse_args()
logging.basicConfig(level=args.log_level)
mcp = CalculationMCPServer("OptimadeServer", port=args.port, host=args.host)


OptimadeAgentName = "optimade_agent"

OptimadeAgentDescription = (
    "An agent specialized in retrieving crystal structure data using the OPTIMADE protocol. "
    "Supports raw OPTIMADE filter strings, space-group-specific queries, and band-gap-specific queries "
    "across multiple materials databases."
)

OptimadeAgentInstruction = """
You are a crystal structure retrieval assistant with access to MCP tools powered by the OPTIMADE API.

## WHAT YOU CAN DO
You can call **three MCP tools**:

1) fetch_structures_with_filter(
       filter: str,
       as_format: 'cif'|'json' = 'cif',
       n_results: int = 2,
       providers: list[str] = [...]
   )
   - Sends ONE raw OPTIMADE filter string to all chosen providers at once.
   You can search for materials using any valid OPTIMADE filter expression, including:
     1. **Element filters** â€” specify required or excluded elements:
        - Must contain all: `elements HAS ALL "Al","O","Mg"`
        - Exactly these: `elements HAS ONLY "Si","O"`
        - Any match: `elements HAS ANY "Al","O"`
     2. **Formula filters** â€” match chemical formulas:
        - Reduced: `chemical_formula_reduced="O2Si"`
        - Descriptive: `chemical_formula_descriptive CONTAINS "H2O"`
        - Anonymous: `chemical_formula_anonymous="A2B"`
     3. **Numeric filters** â€” filter by number of distinct elements:
        - Exactly 3: `nelements=3`
        - Between 2 and 7: `nelements>=2 AND nelements<=7`
     4. **Logical combinations** â€” combine conditions with parentheses:
        - `(elements HAS ANY "Si" AND elements HAS ANY "O") AND NOT (elements HAS ANY "H")`

2) fetch_structures_with_spg(
       base_filter: str,
       spg_number: int,
       as_format: 'cif'|'json' = 'cif',
       n_results: int = 3,
       providers: list[str] = [...]
   )
   - Adds provider-specific *space-group* clauses (e.g., _tcod_sg, _oqmd_spacegroup, _alexandria_space_group) and queries providers in parallel.

3) fetch_structures_with_bandgap(
       base_filter: str,
       min_bg: float | None = None,
       max_bg: float | None = None,
       as_format: 'cif'|'json' = 'json',
       n_results: int = 2,
       providers: list[str] = [...]
   )
   - Adds provider-specific *band-gap* clauses (e.g., _oqmd_band_gap, _gnome_bandgap, _mcloudarchive_band_gap) and queries providers in parallel.
   - For band-gap related tasks, **default output format is 'json'** to include complete metadata.

## HOW TO CHOOSE A TOOL
- If the user wants to filter by **elements / formula / logic only** â†’ you MUST use `fetch_structures_with_filter`
- If the user wants to filter by a **specific space group number (1â€“230)** or a **mineral/structure type** (e.g., rutile, spinel, perovskite) â†’ you MUST use `fetch_structures_with_spg` (you can still combine with a base_filter).
- If the user wants to filter by a **band-gap range** â†’ you MUST use `fetch_structures_with_bandgap` with base_filter and min/max.

## FILTER SYNTAX QUICK GUIDE
- **Equality**: `chemical_formula_reduced="O2Si"`
- **Substring**: `chemical_formula_descriptive CONTAINS "H2O"`
- **Lists**:  
  - HAS ALL: `elements HAS ALL "Al","O","Mg"`
  - HAS ANY: `elements HAS ANY "Si","O"`
  - HAS ONLY: `elements HAS ONLY "Si","O"`
- **Numbers**: `nelements=3`, `nelements>=2 AND nelements<=7`
- **Logic**: Combine with AND, OR, NOT (use parentheses)
- **Exact element set**: `elements HAS ALL "A","B" AND nelements=2`
> ðŸ’¡ **Note**:  
> - If the user provides a concrete chemical formula (e.g., "MgO", "TiO2"), use `chemical_formula_reduced="..."` instead of element filters.  
> - If the user mentions an alloy or specific combination of elements without stoichiometry (e.g., "TiAl åˆé‡‘", "åªåŒ…å« Al å’Œ Zn"), prefer `elements HAS ONLY`.

## MINERAL-LIKE STRUCTURES
Users may ask about specific minerals (e.g., spinel, rutile) or about materials with a certain **structure type** (e.g., spinel-structured, perovskite-structured). These are not always the same: for example, "spinel" usually refers to the compound MgAlâ‚‚Oâ‚„, while "spinel-structured materials" include a family of compounds sharing similar symmetry and composition patterns (ABâ‚‚Câ‚„).
To retrieve such materials:
- Use `chemical_formula_reduced` with space group when referring to a **specific compound** (e.g., â€œMgAlâ‚‚Oâ‚„â€, â€œTiOâ‚‚â€, â€œZnSâ€).
- Use `chemical_formula_anonymous` and/or `elements HAS ANY` when referring to a **structure type family** (e.g., ABCâ‚ƒ, ABâ‚‚Câ‚„).
- Use `fetch_structures_with_spg` when the structure is well-defined by its space group (e.g., rock salt, rutile).
- Use `fetch_structures_with_filter` when structure is inferred from formula or composition pattern.
- âœ… Always **explain to the user** whether you are retrieving a specific mineral compound or a broader structure-type family.
### Examples:
- ç”¨æˆ·ï¼šæ‰¾ä¸€äº›æ–¹é•çŸ³ â†’ Tool: `fetch_structures_with_spg`, `chemical_formula_reduced="MgO"`, `spg_number=225` ï¼ˆæ­¤å¤„ç”¨ spg å› ä¸ºâ€œæ–¹é•çŸ³â€æ˜¯çŸ¿ç‰©åï¼›å¦‚æžœç”¨æˆ·åªå†™â€œMgOâ€ï¼Œåˆ™å¿…é¡»ç”¨ `fetch_structures_with_filter`ï¼‰  
- ç”¨æˆ·ï¼šæŸ¥æ‰¾é‡‘çº¢çŸ³ â†’ Tool: `fetch_structures_with_spg`, `chemical_formula_reduced="O2Ti"`, `spg_number=136` ï¼ˆæ­¤å¤„ç”¨ spg å› ä¸ºâ€œé‡‘çº¢çŸ³â€æ˜¯çŸ¿ç‰©åï¼›å¦‚æžœç”¨æˆ·åªå†™â€œTiO2â€ï¼Œåˆ™å¿…é¡»ç”¨ `fetch_structures_with_filter`ï¼‰  
- ç”¨æˆ·ï¼šæ‰¾ä¸€äº›é’™é’›çŸ¿ç»“æž„çš„ææ–™ â†’ Tool: `fetch_structures_with_filter`, `chemical_formula_anonymous="ABC3"`
- ç”¨æˆ·ï¼šæ‰¾ä¸€ä¸ªé’™é’›çŸ¿ â†’ Tool: `fetch_structures_with_spg`, `chemical_formula_reduced="CaO3Ti"`, `spg_number=221`, `n_results=1` ï¼ˆæ­¤å¤„ç”¨ spg å› ä¸ºâ€œé’™é’›çŸ¿â€æ˜¯çŸ¿ç‰©åï¼›å¦‚æžœç”¨æˆ·åªå†™â€œCaTiO3â€ï¼Œåˆ™å¿…é¡»ç”¨ `fetch_structures_with_filter`ï¼‰  
- ç”¨æˆ·ï¼šæ‰¾ä¸€äº›å°–æ™¶çŸ³ç»“æž„çš„ææ–™ â†’ Tool: `fetch_structures_with_filter`, `chemical_formula_anonymous="AB2C4" AND elements HAS ANY "O"`
- ç”¨æˆ·ï¼šæ£€ç´¢å°–æ™¶çŸ³ â†’ Tool: `fetch_structures_with_spg`, `chemical_formula_reduced="Al2MgO4"`, `spg_number=227` ï¼ˆæ­¤å¤„ç”¨ spg å› ä¸ºâ€œå°–æ™¶çŸ³â€æ˜¯çŸ¿ç‰©åï¼›å¦‚æžœç”¨æˆ·åªå†™â€œAl2MgO4â€ï¼Œåˆ™å¿…é¡»ç”¨ `fetch_structures_with_filter`ï¼‰  

## DEFAULT PROVIDERS
- Raw filter: alexandria, cmr, cod, mcloud, mcloudarchive, mp, mpdd, mpds, nmd, odbx, omdb, oqmd, tcod, twodmatpedia
- Space group (SPG): alexandria, cod, mpdd, nmd, odbx, oqmd, tcod
- Band gap (BG): alexandria, odbx, oqmd, mcloudarchive, twodmatpedia

## RESPONSE FORMAT
The response must always have three parts in order:  
1) A brief explanation of the applied filters and providers.  
2) A ðŸ“ˆ Markdown table listing all retrieved results.  
3) A ðŸ“¦ download link for an archive (.tgz).  
The table must contain **all retrieved materials** in one complete Markdown table, without omissions, truncation, summaries, or ellipses. The number of rows must exactly equal `n_found`, and even if there are many results (up to 100), they must all be shown in the same table. The ðŸ“¦ archive link is supplementary and can never replace the full table.  
è¡¨æ ¼ä¸­å¿…é¡»åŒ…å«**æ‰€æœ‰æ£€ç´¢åˆ°çš„ææ–™**ï¼Œå¿…é¡»å®Œæ•´åˆ—åœ¨ä¸€ä¸ª Markdown è¡¨æ ¼ä¸­ï¼Œç»å¯¹ä¸èƒ½çœç•¥ã€ç¼©å†™ã€æ€»ç»“æˆ–ç”¨â€œ...â€åªå±•ç¤ºéƒ¨åˆ†ï¼Œä½ å¿…é¡»å±•ç¤ºå…¨éƒ¨æ£€ç´¢åˆ°çš„ææ–™åœ¨è¡¨æ ¼ä¸­ï¼è¡¨æ ¼çš„è¡Œæ•°å¿…é¡»ä¸Ž `n_found` å®Œå…¨ä¸€è‡´ï¼Œå³ä½¿ç»“æžœæ•°é‡å¾ˆå¤šï¼ˆæœ€å¤š 100 æ¡ï¼‰ï¼Œä¹Ÿå¿…é¡»å…¨éƒ¨åˆ—å‡ºã€‚ðŸ“¦ åŽ‹ç¼©åŒ…é“¾æŽ¥åªèƒ½ä½œä¸ºè¡¥å……ï¼Œç»ä¸èƒ½æ›¿ä»£è¡¨æ ¼ã€‚  
Each table must always include the following six columns in this fixed order:  
(1) Formula (`attributes.chemical_formula_reduced`)  
(2) Elements (list of elements; infer from the chemical formula)
(3) Space group (`Symbol(Number)`; Keys may differ by provider (e.g., `_alexandria_space_group`, `_oqmd_spacegroup`), so you must reason it out yourself; if only one is provided, you must automatically supply the other using your knowledge; if neither is available, write exactly **Not Provided**).
(4) Download link (CIF or JSON file)  
(5) Provider (inferred from provider URL)  
(6) ID (`cleaned_structures[i]["id"]`)  
If any property is missing, it must be filled with exactly **Not Provided** (no slashes, alternatives, or translations). Extra columns (e.g., lattice vectors, band gap, formation energy) may only be added if explicitly requested; if such data is unavailable, also fill with **Not Provided**.  
If no results are found (`n_found = 0`), clearly state that no matching structures were retrieved, repeat the applied filters, and suggest loosening the criteria, but do not generate an empty table. Always verify that the number of table rows equals `n_found`; if they do not match, regenerate the table until correct. Never claim token or brevity issues, as results are already capped at 100 maximum.

## DEMOS (ç”¨æˆ·é—®é¢˜ â†’ å·¥å…·ä¸Žå‚æ•°)
1) ç”¨æˆ·ï¼šæ‰¾3ä¸ªZrOï¼Œä»Žmpds, cmr, alexandria, omdb, odbxé‡Œé¢æ‰¾  
   â†’ Tool: fetch_structures_with_filter  
     filter: chemical_formula_reduced="OZr"  # æ³¨æ„å…ƒç´ è¦æŒ‰å­—æ¯è¡¨é¡ºåº  
     as_format: "cif"  
     providers: ["mpds", "cmr", "alexandria", "omdb", "odbx"]  
     n_results: 3

2) ç”¨æˆ·ï¼šæ‰¾åˆ°ä¸€äº›A2b3C4çš„ææ–™ï¼Œä¸èƒ½å«æœ‰ Feï¼ŒFï¼ŒClï¼ŒHå…ƒç´ ï¼Œè¦å«æœ‰é“æˆ–è€…é•æˆ–è€…é’ ï¼Œæˆ‘è¦å…¨éƒ¨ä¿¡æ¯ã€‚  
   â†’ Tool: fetch_structures_with_filter  
     filter: chemical_formula_anonymous="A2B3C4" AND NOT (elements HAS ANY "Fe","F","Cl","H") AND (elements HAS ANY "Al","Mg","Na")  
     as_format: "json"

3) ç”¨æˆ·ï¼šæŸ¥æ‰¾ä¸€ä¸ªgammaç›¸çš„TiAlåˆé‡‘  
   â†’ Tool: fetch_structures_with_spg  
     base_filter: elements HAS ONLY "Ti","Al"  
     spg_number: 123  # Î³-TiAl (L1â‚€) å¸¸è®°ä½œ P4/mmmï¼Œä¸º 123ç©ºé—´ç¾¤  
     as_format: "cif"  
     n_results: 1

4) ç”¨æˆ·ï¼šæ£€ç´¢å››ä¸ªå«é“çš„ï¼Œèƒ½å¸¦åœ¨1.0â€“2.0 eV é—´çš„ææ–™  
   â†’ Tool: fetch_structures_with_bandgap  
     base_filter: elements HAS ALL "Al"  
     min_bg: 1.0  
     max_bg: 2.0  
     as_format: "json"  # é»˜è®¤è¾“å‡º json æ ¼å¼ï¼Œé€‚ç”¨äºŽèƒ½å¸¦ç›¸å…³æŸ¥è¯¢  
     n_results: 4

5) ç”¨æˆ·ï¼šæ‰¾ä¸€äº›æ–¹é•çŸ³  
   â†’ Tool: fetch_structures_with_spg  
     base_filter: chemical_formula_reduced="MgO"  
     spg_number: 225
"""


# === TOOL 1: RAW OPTIMADE FILTER ===
@mcp.tool()
async def fetch_structures_with_filter(
    filter: str,
    as_format: Format = "cif",
    n_results: int = 2,
    providers: Optional[List[str]] = None,
) -> FetchResult:
    """
    Fetch crystal structures using a RAW OPTIMADE filter (single request across providers).

    What this does
    --------------
    - Sends the *exact* `filter` string to all selected providers in a single aggregated query.
    - Saves up to `n_results` results per provider in the specified `as_format` ("cif" or "json").

    Arguments
    ---------
    filter : str
        An OPTIMADE filter expression. Examples:
          - elements HAS ALL "Al","O","Mg"
          - elements HAS ONLY "Si","O"
          - chemical_formula_reduced="O2Si"
          - chemical_formula_descriptive CONTAINS "H2O"
          - (elements HAS ANY "Si") AND NOT (elements HAS ANY "H")
    as_format : {"cif","json"}
        Output format for saved structures (default "cif").
    n_results : int
        Number of results to save from EACH provider (default 2).
    providers : list[str] | None
        Providers to query. If omitted, uses DEFAULT_PROVIDERS from utils.py.

    Returns
    -------
    FetchResult
        output_dir: Path to the folder with saved results
        cleaned_structures: List[dict]  # list of cleaned structures
        n_found: int  # number of structures found (0 if none)
    """
    filt = (filter or "").strip()
    if not filt:
        logging.error("[raw] empty filter string")
        return {"output_dir": Path(), "cleaned_structures": [], "n_found": 0}
    filt = normalize_cfr_in_filter(filt)

    used_providers = set(providers) if providers else DEFAULT_PROVIDERS
    
    # Get all URLs for the selected providers (flatten the lists)
    used_urls = [url for provider in used_providers 
                 for url in URLS_FROM_PROVIDERS.get(provider, [])]
    
    logging.info(f"[raw] providers={used_providers} urls={len(used_urls)} filter={filt}")

    try:
        client = OptimadeClient(
            base_urls=used_urls,
            # include_providers=used_providers,
            max_results_per_provider=n_results,
            http_timeout=25.0,
        )
        results = await to_thread.run_sync(lambda: client.get(filter=filt))
    except (SystemExit, Exception) as e:  # catch SystemExit too
        logging.error(f"[raw] fetch failed: {e}")
        return {"output_dir": Path(), "cleaned_structures": [], "n_found": 0}

    # Timestamped folder + short hash of filter for traceability
    tag = filter_to_tag(filt)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    short = hashlib.sha1(filt.encode("utf-8")).hexdigest()[:8]
    out_folder = BASE_OUTPUT_DIR / f"{tag}_{ts}_{short}"

    files, warns, providers_seen, cleaned_structures = await to_thread.run_sync(
        save_structures, results, out_folder, n_results, as_format == "cif"
    )

    manifest = {
        "mode": "raw_filter",
        "filter": filt,
        "providers_requested": sorted(list(used_providers)),
        "providers_seen": providers_seen,
        "files": files,
        "warnings": warns,
        "format": as_format,
        "n_results": n_results,
        "n_found": len(cleaned_structures), 
    }
    (out_folder / "summary.json").write_text(json.dumps(manifest, indent=2))

    cleaned_structures = cleaned_structures[:MAX_RETURNED_STRUCTS]

    return {
        "output_dir": out_folder,
        "cleaned_structures": cleaned_structures,
        "n_found": len(cleaned_structures),
    }


# === TOOL 2: SPACE-GROUP AWARE FETCH (provider-specific fields, parallel) ===
@mcp.tool()
async def fetch_structures_with_spg(
    base_filter: Optional[str],
    spg_number: int,
    as_format: Format = "cif",
    n_results: int = 3,
    providers: Optional[List[str]] = None,
) -> FetchResult:
    """
    Fetch structures constrained by space group number across multiple providers in parallel.

    What this does
    --------------
    - Builds a provider-specific space-group clause (e.g., `_tcod_sg="P m -3 m"`, `_oqmd_spacegroup="Pm-3m"`,
      `_alexandria_space_group=221`, etc.) via `get_spg_filter_map`.
    - Combines it with your optional `base_filter` (elements/formula logic).
    - Runs per-provider queries **in parallel**, then saves all results into one folder.

    Arguments
    ---------
    base_filter : str | None
        Common OPTIMADE filter applied to all providers (e.g., "elements HAS ONLY \"Ti\",\"Al\"").
    spg_number : int
        International space-group number (1-230).
    as_format : {"cif","json"}
        Output format for saved structures (default "cif").
    n_results : int
        Number of results to save from EACH provider (default 3).
    providers : list[str] | None
        Providers to query. If omitted, uses DEFAULT_SPG_PROVIDERS from utils.py.

    Returns
    -------
    FetchResult
        output_dir: Path to the folder with saved results
        cleaned_structures: List[dict]  # list of cleaned structures
        n_found: int  # number of structures found (0 if none)
    """
    base = (base_filter or "").strip()
    base = normalize_cfr_in_filter(base)
    used = set(providers) if providers else DEFAULT_SPG_PROVIDERS

    # Build provider-specific SPG clauses and combine with base filter
    spg_map = get_spg_filter_map(spg_number, used)
    filters = build_provider_filters(base, spg_map)
    if not filters:
        logging.warning("[spg] no provider-specific space-group clause available")
        return {"output_dir": Path(), "cleaned_structures": [], "n_found": 0}

    async def _query_one(provider: str, clause: str) -> dict:
        logging.info(f"[spg] {provider}: {clause}")
        try:
            # Get all URLs for this provider (flatten the lists)
            provider_urls = [url for url in URLS_FROM_PROVIDERS.get(provider, [])]
            if not provider_urls:
                logging.warning(f"[spg] No URLs found for provider {provider}")
                return {"structures": {}}
                
            client = OptimadeClient(
                base_urls=provider_urls,
                max_results_per_provider=n_results,
                http_timeout=25.0,
            )
            return await to_thread.run_sync(lambda: client.get(filter=clause))
        except (SystemExit, Exception) as e:  # catch SystemExit too
            logging.error(f"[spg] fetch failed for {provider}: {e}")
            return {"structures": {}}

    # Parallel fanâ€‘out per provider
    results_list = await asyncio.gather(
        *[_query_one(p, clause) for p, clause in filters.items()],
        return_exceptions=True,  # don't cancel all on one failure
    )

    # Turn any exceptions into empty result dicts
    norm_results = []
    for r in results_list:
        if isinstance(r, Exception):
            logging.error(f"[spg] task returned exception: {r}")
            norm_results.append({"structures": {}})
        else:
            norm_results.append(r)

    # Save all results together
    tag = filter_to_tag(f"{base} AND spg={spg_number}")
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    short = hashlib.sha1(f"{base}|spg={spg_number}".encode("utf-8")).hexdigest()[:8]
    out_folder = BASE_OUTPUT_DIR / f"{tag}_{ts}_{short}"

    all_files: List[str] = []
    all_warnings: List[str] = []
    all_providers: List[str] = []
    all_cleaned: List[dict] = []
    for res in norm_results:
        files, warns, providers_seen, cleaned = await to_thread.run_sync(
            save_structures, res, out_folder, n_results, as_format == "cif"
        )
        all_files.extend(files)
        all_warnings.extend(warns)
        all_providers.extend(providers_seen)
        all_cleaned.extend(cleaned)

    manifest = {
        "mode": "space_group",
        "base_filter": base,
        "spg_number": spg_number,
        "providers_requested": sorted(list(used)),
        "providers_seen": all_providers,
        "files": all_files,
        "warnings": all_warnings,
        "format": as_format,
        "n_results": n_results,
        "per_provider_filters": filters,
        "n_found": len(all_cleaned),
    }
    (out_folder / "summary.json").write_text(json.dumps(manifest, indent=2))

    all_cleaned = all_cleaned[:MAX_RETURNED_STRUCTS]

    return {
        "output_dir": out_folder,
        "cleaned_structures": all_cleaned,
        "n_found": len(all_cleaned),
    }


# === TOOL 3: BANDâ€‘GAP RANGE FETCH (provider-specific fields, parallel) ===
@mcp.tool()
async def fetch_structures_with_bandgap(
    base_filter: Optional[str],
    min_bg: Optional[float] = None,
    max_bg: Optional[float] = None,
    as_format: Format = "cif",
    n_results: int = 2,
    providers: Optional[List[str]] = None,
) -> FetchResult:
    """
    Fetch structures constrained by band-gap range across multiple providers in parallel.

    What this does
    --------------
    - Resolves provider-specific band-gap property names (e.g., `_oqmd_band_gap`, `_gnome_bandgap`,
      `_mcloudarchive_band_gap`, etc.) via `get_bandgap_filter_map`.
    - Builds a per-provider band-gap clause (min/max inclusive), combines with your optional `base_filter`.
    - Runs each provider query **in parallel**, then saves all results into one folder.

    Arguments
    ---------
    base_filter : str | None
        Common OPTIMADE filter applied to all providers (e.g., 'elements HAS ALL "Al"').
    min_bg, max_bg : float | None
        Band-gap range in eV (open-ended allowed, e.g., min only or max only).
    as_format : {"cif","json"}
        Output format for saved structures (default "cif").
    n_results : int
        Number of results to save from EACH provider (default 2).
    providers : list[str] | None
        Providers to query; if None, uses DEFAULT_BG_PROVIDERS from utils.py.

    Returns
    -------
    FetchResult
        output_dir: Path to the folder with saved results
        cleaned_structures: List[dict]  # list of cleaned structures
        n_found: int  # number of structures found (0 if none)
    """
    base = (base_filter or "").strip()
    base = normalize_cfr_in_filter(base)
    used = set(providers) if providers else DEFAULT_BG_PROVIDERS

    # Build per-provider bandgap clause and combine with base
    bg_map = get_bandgap_filter_map(min_bg, max_bg, used)
    filters = build_provider_filters(base, bg_map)

    if not filters:
        logging.warning("[bandgap] no provider-specific band-gap clause available")
        return {"output_dir": Path(), "cleaned_structures": [], "n_found": 0}

    async def _query_one(provider: str, clause: str) -> dict:
        logging.info(f"[bandgap] {provider}: {clause}")
        try:
            # Get all URLs for this provider (flatten the lists)
            provider_urls = [url for url in URLS_FROM_PROVIDERS.get(provider, [])]
            if not provider_urls:
                logging.warning(f"[bandgap] No URLs found for provider {provider}")
                return {"structures": {}}
                
            client = OptimadeClient(
                base_urls=provider_urls,
                max_results_per_provider=n_results,
                http_timeout=25.0,
            )
            return await to_thread.run_sync(lambda: client.get(filter=clause))
        except (SystemExit, Exception) as e:  # catch SystemExit too
            logging.error(f"[bandgap] fetch failed for {provider}: {e}")
            return {"structures": {}}

    # Parallel fanâ€‘out per provider
    results_list = await asyncio.gather(
        *[_query_one(p, clause) for p, clause in filters.items()],
        return_exceptions=True,  # don't cancel all on one failure
    )
    norm_results = []
    for r in results_list:
        if isinstance(r, Exception):
            logging.error(f"[bandgap] task returned exception: {r}")
            norm_results.append({"structures": {}})
        else:
            norm_results.append(r)

    # Save all results together
    tag = filter_to_tag(f"{base} AND bandgap[{min_bg},{max_bg}]")
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    short = hashlib.sha1(f"{base}|bg={min_bg}:{max_bg}".encode("utf-8")).hexdigest()[:8]
    out_folder = BASE_OUTPUT_DIR / f"{tag}_{ts}_{short}"

    all_files: List[str] = []
    all_warnings: List[str] = []
    all_providers: List[str] = []
    all_cleaned: List[dict] = []
    for res in norm_results:
        files, warns, providers_seen, cleaned = await to_thread.run_sync(
            save_structures, res, out_folder, n_results, as_format == "cif"
        )
        all_files.extend(files)
        all_warnings.extend(warns)
        all_providers.extend(providers_seen)
        all_cleaned.extend(cleaned)

    manifest = {
        "mode": "band_gap",
        "base_filter": base,
        "band_gap_min": min_bg,
        "band_gap_max": max_bg,
        "providers_requested": sorted(list(used)),
        "providers_seen": all_providers,
        "files": all_files,
        "warnings": all_warnings,
        "format": as_format,
        "n_results": n_results,
        "per_provider_filters": filters,
        "n_found": len(all_cleaned),
    }
    (out_folder / "summary.json").write_text(json.dumps(manifest, indent=2))

    all_cleaned = all_cleaned[:MAX_RETURNED_STRUCTS]

    return {
        "output_dir": out_folder,
        "cleaned_structures": all_cleaned,
        "n_found": len(all_cleaned),
    }


# === RUN MCP SERVER ===
if __name__ == "__main__":
    logging.info("Starting Optimade MCP Serverâ€¦")
    mcp.run(transport="sse")